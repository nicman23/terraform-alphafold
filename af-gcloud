#!/bin/bash

source $(dirname $(realpath $0))/lib.sh

template=a100-af

create_and_send () {
  name=''
  success=0
  for name in $(eval echo $(list_running)); do
    if sssh ls /root/final_done; then
      success=1
      break
    fi
  done

  if [ "$success" -eq 0 ]; then
  name="vm-$(uuidgen)"
    create_vm $template echo
    while ! sssh true; do
      sleep 2
    done
  else
    echo found avail vm $name
    sssh rm final_done
  fi

(
  af_do_work $1

  delete_vm
) &
}

af_do_work() {

  (
    cat $1 | sssh 'zstd -d | tar -xf -'
  ) &>> ${name}.sender.log

  cat << EOF | sssh cat - \> work.sh
  ln -fs /root/mlibs /root/public_databases
  mkdir af_output workdir
  cd af_input
  rm /root/work_done /root/final_done
  for i in *json; do
    mkdir -p /root/workdir/\$i
    [ -e /root/af_output/\$i ] && continue
    mkdir -p /root/workdir/\$i/msa_outputs /root/af_input/\$i/msa_outputs
    docker kill main
    docker rm main
    docker run --name main -d  \
      --volume /root/:/root/ \
      --gpus=all \
      alphafold3 \
      python run_alphafold.py \
      --run_inference=True \
      --run_data_pipeline=False \
      --json_path=/root/af_input/\$i \
      --model_dir=/root/models \
      --output_dir=/root/workdir/\$i
    docker wait main
    docker logs main > /root/workdir/\$i/log
    docker rm main
    mv /root/workdir/\$i /root/af_output/
    echo \$i >> /root/work_done

  done
  touch /root/final_done
EOF

### fetcher thread ###
(
  sleep 1m
  while ! sssh cat final_done; do
    sleep 10m
    if sssh cat work_done; then
      fetcher
    fi
  done
  touch af_output/final_done
)  &>> ${name}.fetch.log &

  while ! sssh cat final_done; do
    sssh 'bash work.sh' &>> ${name}.work.log ||
    check_health
  done
  fetcher
  touch af_output/final_done
}

fetcher() {
  buf="$(sssh cat work_done)"
  for l in $buf; do
    mkdir -p af_output/workdir/
    srsync /root/af_output/$l af_output/workdir/$l
    mv af_output/$l af_output/$l
  done
  sssh rm work_done
}

get_msa_too() {
  (
  set +e
  while read l ; do
    echo $l;  jq < $l | grep Path\": | rev | cut -f2 -d\" | rev | sed 's~^~./af_input/~g';
  done 2>/dev/null
  )
}

cleanup() {
  rm -rf ${tmpfiles[@]} af_output/workdir/

  kill $(jobs -p)
}

fancy() {
  input=af_input
  output=af_output
  total=$(ls $input | wc -l)

  (
  cur=0
  prev=0

  while [ $total -gt $cur ]; do
    cur=$(ls $output | wc -l)
    diff=$((cur - prev))
    seq 0 $diff | sed 1d
    prev=$cur
    sleep 1
  done
  ) |
  pv -l -s $total > /dev/null
}

if [ -z "$STY" ]; then
  echo must be run from a \(GNU\) screen
  exit
fi

###no service account
#bash /home/gcloudPuppet/terraform-alphafold/auth.sh
# while true; do sleep 12h;
#   bash /home/gcloudPuppet/terraform-alphafold/auth.sh
# done &

if ! ls af_input/*json &>/dev/null; then
echo af_input empty
exit 2
fi
mkdir -p af_output

#pubkey=$(cat $(ls ~/.ssh/*pub | head -n1) )

already_done=( $(cd af_output ; ls | sed 's~^~af_input/~g') )
files=( $(find af_input -name \*json | while read l; do [[  "${already_done[@]}" =~ "$l"  ]] || echo $l; done) ) > /dev/null
files_m=$(( ${#files[@]} -1 ))
max_vms=8
#max_vms=$((max_vms -1 ))
step=$(( files_m / max_vms ))
files_i=0

#tmpfiles=( $PWD/af_output/workdir/ )
tmpfiles=()

trap cleanup EXIT
trap cleanup ERR

echo refreshing state please wait
refresh_state

while [ $files_m -ge $files_i ] ; do
  t_d=$(mktemp -dp .)
  tmpfiles+=($PWD/$t_d/)

  for i in `seq $files_i $(( step + files_i ))`; do
    echo ${files[$i]}
  done | get_msa_too > $t_d/part.txt
  files_i=$(( files_i + step + 1 ))

  tar -cf - -T $t_d/part.txt |
  zstd -1 > $t_d/af_input.tar.zst
  rm $t_d/part.txt

  create_and_send $PWD/$t_d/af_input.tar.zst
done

fancy
